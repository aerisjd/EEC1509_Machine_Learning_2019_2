{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lesson#01 - Linear Algebra for Machine Learning.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dqjp2Oik1Utg","colab_type":"text"},"source":["# 1. Introduction"]},{"cell_type":"markdown","metadata":{"id":"QAkyg5Qp1RrJ","colab_type":"text"},"source":["There is no doubt that linear algebra is important in machine learning. **Linear algebra is the\n","mathematics of data**. \n","\n","- It's all vectors and matrices of numbers. \n","\n","Modern statistics is described using the notation of linear algebra and modern statistical methods harness the tools of linear algebra. Modern machine learning methods are described the same way, using the notations and tools drawn directly from linear algebra. Even some classical methods used in the old, such as **linear regression** via linear least squares and singular-value decomposition, are linear algebra methods, and other methods, such as **principal component analysis**, were born from the\n","marriage of linear algebra and statistics. To read and understand machine learning, you must\n","be able to read and understand linear algebra.\n","\n","\n","**This lesson will teach you the basics of linear algebra that you need to know as a machine learning practitioner**. After reading and working through this lesson, you will know:\n","\n","- What linear algebra is and why it is relevant and important to machine learning.\n","- How to create, index, and generally manipulate data in NumPy arrays.\n"]},{"cell_type":"markdown","metadata":{"id":"4WLBQwVJNyip","colab_type":"text"},"source":["## 1.1 Practitioners Study Linear Algebra Too Early"]},{"cell_type":"markdown","metadata":{"id":"YH2l1-4AN2vE","colab_type":"text"},"source":["If you ask how to get started in machine learning, you will very likely be told to start with\n","linear algebra. We know that knowledge of linear algebra is critically important, but it does\n","not have to be the place to start. Learning linear algebra first, then calculus, probability,\n","statistics, and eventually machine learning theory is a long and slow bottom-up path.\n","\n","<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1bVQew_0bH_zEqfpmU2o9UqnHYvlqM4dX\">\n","\n","\n","**A better fit for developers** is to start with systematic procedures that get results, and work back to the deeper understanding of theory, using working results as a context. I call this the top-down or results first approach to machine learning, and linear algebra is not the first step, but perhaps the second or third.\n","\n","<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=15RPXM3sPdMz3gpiBxWgfNsg-x3KrAldP\">"]},{"cell_type":"markdown","metadata":{"id":"_tSdkUMYZDaL","colab_type":"text"},"source":["## 1.2 Examples of Linear Algebra in Machine Learning "]},{"cell_type":"markdown","metadata":{"id":"MuldsopRZBV9","colab_type":"text"},"source":["Linear algebra is a sub-field of mathematics concerned with:\n","- vectors\n","- matrices\n","- linear transforms. \n","\n","It is a key foundation to the field of machine learning from notations used to\n","describe the operation of algorithms, to the implementation of algorithms in code. Although\n","linear algebra is integral to the field of machine learning, the tight relationship is often left\n","unexplained or explained using abstract concepts such as vector spaces or specific matrix\n","operations. In this section, you will discover 10 common examples of machine learning that\n","you may be familiar with that use, require and are really best understood using linear algebra.\n","\n","1. Dataset and Data Files\n","2. Images and Photographs\n","3. One Hot Encoding\n","4. Linear Regression\n","5. Regularization\n","6. Principal Component Analysis\n","7. Singular-Value Decomposition\n","8. Latent Semantic Analysis\n","9. Recommender Systems\n","10. Deep Learning"]},{"cell_type":"markdown","metadata":{"id":"mVaSwPC0Zd2q","colab_type":"text"},"source":["### 1.2.1 Dataset and Data Files"]},{"cell_type":"markdown","metadata":{"id":"vLZYD4yIaArU","colab_type":"text"},"source":["In machine learning, you fit a model on a dataset. This is the table like set of numbers where\n","each row represents an observation and each column represents a feature of the observation. For example, below is a snippet of the [Iris flowers dataset](http://archive.ics.uci.edu/ml/datasets/Iris).\n","\n","```python\n","5.1,3.5,1.4,0.2,Iris-setosa\n","4.9,3.0,1.4,0.2,Iris-setosa\n","4.7,3.2,1.3,0.2,Iris-setosa\n","4.6,3.1,1.5,0.2,Iris-setosa\n","5.0,3.6,1.4,0.2,Iris-setosa\n","...\n","```\n","\n","**This data is in fact a matrix**, a key data structure in linear algebra. Further, when you\n","split the data into inputs and outputs to fit a **supervised machine learning model**, such as the measurements and the  ower species, you have a matrix $(X)$ and a vector $(y)$. The **vector** is another key data structure in linear algebra. \n","\n","- Each row has the same length, i.e. the same number of columns\n","\n","therefore, we can say that the data is vectorized where rows can be provided\n","to a model one at a time or in batch and the model can be pre-configured to expect rows of a\n","fixed width."]},{"cell_type":"markdown","metadata":{"id":"1A3LuhQEaWNo","colab_type":"text"},"source":["### 1.2.2 Images and Photographs\n"]},{"cell_type":"markdown","metadata":{"id":"Is8XmOz1bc_G","colab_type":"text"},"source":["\n","Perhaps you are more used to working with images or photographs in computer vision applications.\n","Each image that you work with is itself a table structure with a width and height and one pixel\n","value in each cell for black and white images or 3 pixel values in each cell for a color image. A\n","photo is yet another example of a matrix from linear algebra. Operations on the image, such\n","as cropping, scaling, shearing and so on are all described using the notation and operations of\n","linear algebra."]},{"cell_type":"markdown","metadata":{"id":"GBkGJOstb9GI","colab_type":"text"},"source":["### 1.2.3 One Hot Encoding\n"]},{"cell_type":"markdown","metadata":{"id":"H_pEsLD9b_Ro","colab_type":"text"},"source":["\n","Sometimes you work with **categorical data** in machine learning. Perhaps the class labels for classification problems, or perhaps categorical input variables. It is common to encode categorical variables to make their easier to work with and learn by some techniques. A popular encoding for categorical variables is the **one hot encoding**. A one hot encoding is where a table is created to represent the variable with one column for each category and a row for each example in the dataset. A check or one-value is added in the column for the categorical value for a given row, and a zero-value is added to all other columns. For example, the variable color variable with the 3 rows:\n","\n","```python\n","red\n","green\n","blue\n","...\n","```\n","\n","Might be encoded as:\n","\n","```python\n","red, green, blue\n","1, 0, 0\n","0, 1, 0\n","0, 0, 1\n","...\n","```\n","\n","Each row is encoded as a binary vector, a vector with zero or one values and this is an\n","example of a **sparse representation**, a whole sub-field of linear algebra."]},{"cell_type":"markdown","metadata":{"id":"Pge3rOuGcVTv","colab_type":"text"},"source":["### 1.2.4 Linear Regression\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LtEJ2_svc8H3","colab_type":"text"},"source":["\n","Linear regression is an old method from statistics for describing the relationships between\n","variables. It is often used in machine learning for predicting numerical values in simpler\n","regression problems. There are many ways to describe and solve the linear regression problem, i.e. finding a set of coeficients that when multiplied by each of the input variables and added together results in the best prediction of the output variable. If you have used a machine learning tool or library, the most common way of solving linear regression is via a least squares optimization that is solved using matrix factorization methods from linear regression, such as an **LU decomposition** or an **singular-value decomposition** or SVD. Even the common way of summarizing the linear regression equation uses linear algebra notation:\n","\n","$\n","y = A \\cdot b\n","$\n","\n","Where $y$ is the output variable $A$ is the dataset and $b$ are the model coeficients."]},{"cell_type":"markdown","metadata":{"id":"gIVdCsXsdJhB","colab_type":"text"},"source":["### 1.2.5 Regularization\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UMP0nExoeFui","colab_type":"text"},"source":["\n","In applied machine learning, we often seek the simplest possible models that achieve the best\n","skill on our problem. \n","\n","Simpler models are often better at generalizing from specific examples to unseen data. In many methods that involve coeficients, such as **regression methods** and\n","**artificial neural networks**, simpler models are often characterized by models that have smaller coeficient values. A technique that is often used to encourage a model to minimize the size of coeficients while it is being fit on data is called **regularization**. Common implementations include the $L^2$ and $L^1$ forms of regularization. Both of these forms of regularization are in fact a measure of the magnitude or length of the coeficients as a vector and are methods lifted directly from linear algebra called the **vector norm**."]},{"cell_type":"markdown","metadata":{"id":"b3ZBZDn5eh36","colab_type":"text"},"source":["### 1.2.6 Principal Component Analysis\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5dT3GY92ewvM","colab_type":"text"},"source":["\n","Often a dataset has many columns, perhaps tens, hundreds, thousands or more. Modeling data with many features is challenging, and models built from data that include irrelevant features are often less skillful than models trained from the most relevant data. It is hard to know which features of the data are relevant and which are not. Methods for automatically reducing the number of columns of a dataset are called **dimensionality reduction**, and perhaps the most popular is method is called the **principal component analysis** or PCA for short. \n","\n","This method is used in machine learning to create projections of high-dimensional data for both visualization and for training models. The core of the PCA method is a matrix factorization method from linear algebra. The eigendecomposition can be used and more robust implementations may use the singular-value decomposition or SVD."]},{"cell_type":"markdown","metadata":{"id":"Gd9cHFVBfEZR","colab_type":"text"},"source":["### 1.2.7 Singular-Value Decomposition\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EFJeztAVfLZM","colab_type":"text"},"source":["\n","Another popular dimensionality reduction method is the singular-value decomposition method\n","or SVD for short. As mentioned and as the name of the method suggests, it is a matrix\n","factorization method from the field of linear algebra. It has wide use in linear algebra and can\n","be used directly in applications such as **feature selection**, visualization, noise reduction and more. We will see two more cases below of using the SVD in machine learning."]},{"cell_type":"markdown","metadata":{"id":"vJA7JZlnf_kk","colab_type":"text"},"source":["### 1.2.8 Latent Semantic Analysis (LSA)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CdybTMLXgDQ8","colab_type":"text"},"source":["\n","In the sub-field of machine learning for working with text data called **natural language processing**, it is common to represent documents as large matrices of word occurrences. For example, the columns of the matrix may be the known words in the vocabulary and rows may be sentences, paragraphs, pages or documents of text with cells in the matrix marked as the count or frequency of the number of times the word occurred. This is a **sparse matrix** representation of the text.\n","\n","Matrix factorization methods such as the singular-value decomposition can be applied to this\n","sparse matrix which has the efect of distilling the representation down to its most relevant\n","essence. Documents processed in thus way are much easier to compare, query and use as the basis for a supervised machine learning model. This form of data preparation is called Latent Semantic Analysis or LSA for short, and is also known by the name Latent Semantic Indexing or LSI."]},{"cell_type":"markdown","metadata":{"id":"SWxN9J1QgURv","colab_type":"text"},"source":["### 1.2.9 Recommender Systems\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T8DlWVFvg0pB","colab_type":"text"},"source":["\n","Predictive modeling problems that involve the recommendation of products are called **recommender systems**, a sub-field of machine learning. Examples include the recommendation of books based on previous purchases and purchases by customers like you on Amazon, and the recommendation of movies and TV shows to watch based on your viewing history and viewing history of subscribers like you on Netflix. **The development of recommender systems is primarily concerned with linear algebra methods**. A simple example is in the calculation of the similarity between sparse customer behavior vectors using distance measures such as **Euclidean distance\n","or dot products**. Matrix factorization methods like the **singular-value decomposition** are used widely in recommender systems to distill item and user data to their essence for querying and searching and comparison."]},{"cell_type":"markdown","metadata":{"id":"SCBMIyzShFdu","colab_type":"text"},"source":["### 1.2.10 Deep Learning\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_2ggbg5DhYPx","colab_type":"text"},"source":["\n","Artificial neural networks are nonlinear machine learning algorithms that are inspired by elements of the information processing in the brain and have proven efective at a range of problems not least predictive modeling. \n","\n","Deep learning is the recent resurged use of artificial neural networks\n","with newer methods and faster hardware that allow for the development and training of larger\n","and deeper (more layers) networks on very large datasets. Deep learning methods are routinely achieve state-of-the-art results on a range of challenging problems such as machine translation, photo captioning, speech recognition and much more.\n","\n","At their core, the execution of neural networks involves linear algebra data structures\n","multiplied and added together. Scaled up to multiple dimensions, **deep learning methods work\n","with vectors, matrices and even tensors of inputs and coeficients, where a tensor is a matrix\n","with more than two dimensions**. Linear algebra is central to the description of deep learning\n","methods via matrix notation to the implementation of deep learning methods such as Google's TensorFlow Python library that has the word \"tensor\" in its name."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HII0h3cE4VdX","toc-hr-collapsed":true},"source":["# 2. Introduction to Numpy\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Al_XlJ3-6HVf"},"source":["## 2.1  Understanding Vectorization\n"]},{"cell_type":"markdown","metadata":{"id":"AQ1oqFOP0T62","colab_type":"text"},"source":["\n","One of the reasons that the Python language is extremely popular is that it makes writing programs easy. When we execute Python code, the Python interpreter converts your code into bytecode that your computer can understand, and then runs that [bytecode](https://en.wikipedia.org/wiki/Bytecode). When you write code in Python, you don't have to worry about things like allocating memory on your computer or choosing how certain operations are done by your computer's processor. Python takes care of that for you.\n","\n","<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1WSCD15qS89t5di-x-_WjLHwI6-Tj9EeH\">\n","\n","Python is what we call a **high-level language**. High level languages allow you to write programs faster as the interpreter makes the decisions on how to execute your instructions. In contrast, when you use **low-level** languages like C, you define exactly how memory will be managed and how the processor will execute your instructions. This means that coding in a **low-level language** takes longer, however you have more ability to optimize your code to run faster.\n","\n","| Language Type | Example | Time taken to write program | Control over program performance |\n","|---------------|---------|-----------------------------|----------------------------------|\n","| High-Level | Python | Low | Low |\n","| Low-Level | C | High | High |\n","\n","When choosing between a high and low-level language, you have to make a trade-off between being able to work and quickly, and having programs that run quickly and efficiently. Luckily, there are two Python libraries that were created to give us the best of both-worlds: **NumPy** and **pandas**. Together, pandas and NumPy provide a powerful toolset for working with data in Python. They allow us to write code quickly without sacrificing performance. But how do they do this? What is it that makes these libraries faster than raw Python? The answer is **vectorization**.\n","\n","\n","**How Vectorization Makes Code Faster**\n","\n","Let's look at an example where we have two columns of data. Each row contains two numbers we wish to add together. Using just Python, we would use a list of lists structure to store our data, and use for loops to iterate over that data. Let's see what this would look like as Python code:\n","\n","\n","<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=15rYQH5ne_AhjfSzSzsXdV2AdD7LKRsrl\">\n","\n","\n","When this code is run, the Python interpreter will turn our code into bytecode, following the logic of our **for** loop. In each iteration of our loop, the bytecode asks our computer's processor to add the two numbers together and stores the result. The diagram shows the first calculation our computer's processor would make:\n","\n","<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=10qEvWGmvAHbT1NcqW6D8DjmZzPh08_TZ\">\n","\n","\n","Our computer would take eight processor cycles to process the 8 rows of of our data.\n","\n","Vectorization takes advantage of a processor feature called **Single Instruction Multiple Data (SIMD)** to process data faster. Most modern computer processors support SIMD. SIMD allows a processor to perform the same operation, on multiple data points, in a single processor cycle. Let's look at how a vectorized version of our code above might be processed using a SIMD instruction that allows four data points to be processed at once:\n","\n","\n","<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1DY8rZ_TtTrOOmG4qWgaEJcVE4vlJAhJc\">\n","\n","As a result, the NumPy version of our code would only take two processor cycles — a four times speed-up! This concept of replacing for loops with operations applied to multiple data points at once is called **vectorization**.\n","\n","The core data structure in NumPy that makes vectorization possible is the **ndarray** or **n-dimensional array**. In programming, **array** describes a collection of elements, similar to a list. The word n-dimensional refers to the fact that ndarrays can have one or more dimensions. We'll start by first working with one-dimensional (1D) ndarrays.\n","\n","<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1rTyYqAgo2gzhPCJE6-teIQgCefwn-1e7\">"]},{"cell_type":"markdown","metadata":{"id":"WP6lKEhp4-Oa","colab_type":"text"},"source":["To use the NumPy library, we first need to import it into our Python environment. NumPy is commonly imported using the alias **np**:\n","\n","```python\n","import numpy as np\n","```\n","Then, we can directly convert a list to an ndarray using the [numpy.array() constructor](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.array.html). To create a 1D ndarray, we can pass in a single list:\n","\n","```python\n","data_ndarray = np.array([5, 10, 15, 20])\n","type(data_ndarray)\n","```\n","\n","Let's practice creating 1D ndarrays next.\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Import numpy and assign to the alias **np**.\n","- Create a NumPy ndarray from the list [10, 20, 30]. Assign the result to the variable **data_ndarray**."]},{"cell_type":"code","metadata":{"id":"yahm89Y_6XzV","colab_type":"code","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FzdtDuU266BC"},"source":["## 2.2 NYC Taxi-Airport Data\n"]},{"cell_type":"markdown","metadata":{"id":"nRlIK_l-2XKT","colab_type":"text"},"source":["\n","In the last subsection, we practiced creating a 1D ndarray. However, ndarrays can also be two-dimensional:\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1aD6Kw9TSlwEjkPXLMHGNskhkfaSWURmT\">\n","\n","\n","As we learn about two-dimensional (2D) ndarrays, we'll analyze [taxi trip data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) released by the city of New York.\n","\n","\n","<center>\n","<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1CjDo9pWq9g7bKjNH_Xo6cLUj17yf-f2f\">\n","</center>\n","\n","We'll only work with a subset of this data - approximately 90,000 yellow taxi trips to and from New York City airports between January and June 2016. Below is information about selected columns from the data set:\n","\n","- **pickup_year** - The year of the trip.\n","- **pickup_month** - The month of the trip (January is 1, December is 12).\n","- **pickup_day** - The day of the month of the trip.\n","- **pickup_location_code** - The airport or borough where the the trip started, as one of eight categories:\n","  - 0 - Bronx.\n","  - 1 - Brooklyn.\n","  - 2 - JFK Airport.\n","  - 3 - LaGuardia Airport.\n","  - 4 - Manhattan.\n","  - 5 - Newark Airport.\n","  - 6 - Queens.\n","  - 7 - Staten Island.\n","- **dropoff_location_code** - The airport or [borough](https://en.wikipedia.org/wiki/Boroughs_of_New_York_City) where the the trip finished, using the same eight category codes as **pickup_location_code**.\n","- **trip_distance** - The distance of the trip in miles.\n","- **trip_length** - The length of the trip in seconds.\n","- **fare_amount** - The base fare of the trip, in dollars.\n","- **total_amount** - The total amount charged to the passenger, including all fees, tolls and tips.\n","\n","You can find information on all columns in the [dataset data dictionary](https://docs.google.com/document/d/1zLZspwkGFjrqpspkZNipIM0790gPI1-rMhOcIsUmD7A/edit?usp=sharing).\n","\n","Our data is stored in a CSV file called **nyc_taxis.csv**. Below are the first few lines of raw data in our CSV (we are showing only the first four columns from the file to make the format easier to understand):\n","\n","```python\n","pickup_year,pickup_month,pickup_day,pickup_dayofweek\n","2016,1,1,5\n","2016,1,1,5\n","2016,1,1,5\n","2016,1,1,5\n","```\n","\n","You may notice that the data could also be represented in a table form:\n","\n","| pickup_year | pickup_month | pickup_day | pickup_dayofweek | pickup_time | pickup_location_code | dropoff_location_code | trip_distance | trip_length | fare_amount | total_amount |\n","|-------------|--------------|------------|------------------|-------------|----------------------|-----------------------|---------------|-------------|-------------|--------------|\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 4 | 21.00 | 2037 | 52.0 | 69.99 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 1 | 16.29 | 1520 | 45.0 | 54.30 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 6 | 12.70 | 1462 | 36.5 | 37.80 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 6 | 8.70 | 1210 | 26.0 | 32.76 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 6 | 5.56 | 759 | 17.5 | 18.80 |\n","| 2016 | 1 | 1 | 5 | 0 | 4 | 2 | 21.45 | 2004 | 52.0 | 105.60 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 6 | 8.45 | 927 | 24.5 | 32.25 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 6 | 7.30 | 731 | 21.5 | 22.80 |\n","| 2016 | 1 | 1 | 5 | 0 | 2 | 5 | 36.30 | 2562 | 109.5 | 131.38 |\n","| 2016 | 1 | 1 | 5 | 0 | 6 | 2 | 12.46 | 1351 | 36.0 | 37.30 |\n","\n","\n","Does this look familiar? Scroll up and compare this table to the diagram of the 2D ndarray above. You can picture 2D ndarrays as storing data like this table.\n","\n","To convert the data set into a 2D ndarray, we'll first use Python's [built-in csv module](https://docs.python.org/3/library/csv.html) to import our CSV as a \"list of lists.\" Then, we'll convert the list of lists to an ndarray. We'll again use the numpy.array() constructor, but to create a 2D ndarray, we'll pass in our list of lists instead of a single list:\n","\n","```python\n","# our list of lists is stored as data_list\n","data_ndarray = np.array(data_list)\n","```\n","\n","\n","\n","Let's convert our taxi CSV into a NumPy ndarray!\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","In the code below we have used Python's csv module to import the **nyc_taxis.csv** file and convert it to a list of lists containing float values.\n","\n","- Add a line of code using the numpy.array() constructor to convert the **converted_taxi_list** variable to a NumPy ndarray.\n","- Assign the result to the variable name **taxi**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pTfQJFbQ_YnE","colab":{}},"source":["import csv\n","import numpy as np\n","\n","# import nyc_taxi.csv as a list of lists\n","f = open(\"nyc_taxis.csv\", \"r\")\n","taxi_list = list(csv.reader(f))\n","\n","# remove the header row\n","taxi_list = taxi_list[1:]\n","\n","# convert all values to floats\n","converted_taxi_list = []\n","for row in taxi_list:\n","    converted_row = []\n","    for item in row:\n","        converted_row.append(float(item))\n","    converted_taxi_list.append(converted_row)\n","\n","# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"51K0evCeIY2-"},"source":["## 2.3  Arrays shapes\n"]},{"cell_type":"markdown","metadata":{"id":"BoXqJkRIBVtW","colab_type":"text"},"source":["\n","Let's take a look at the data in the taxi variable from the previous subsection by printing it using [Python's print() function](https://docs.python.org/3.4/library/functions.html#print):\n","\n","```python\n","print(taxi)\n","\n","    [[ 2016.  1.   1.  ..., 11.65  69.99   1. ]\n","     [ 2016.  1.   1.  ...,  8.    54.3    1. ]\n","     [ 2016.  1.   1.  ...,  0.    37.8    2. ]\n","     ..., \n","     [ 2016.  6.  30.  ...,  5.    63.34   1. ]\n","     [ 2016.  6.  30.  ...,  8.95  44.75   1. ]\n","     [ 2016.  6.  30.  ...,  0.    54.84   2. ]]\n","```\n","\n","The elipses (...) between rows and columns indicate that there is more data in our NumPy ndarray than can easily be printed.\n","\n","However, it's often useful to know the number of rows and columns in an ndarray. When we can't easily print the entire ndarray, we can use the [ndarray.shape](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.ndarray.shape.html#numpy.ndarray.shape) attribute instead:\n","\n","```python\n","data_ndarray = np.array([[5, 10, 15], \n","                         [20, 25, 30]])\n","print(data_ndarray.shape)\n","(2,3)\n","````\n","\n","The data type returned is called a **tuple**. Tuples are very similar to Python lists, but can't be modified.\n","\n","The output gives us a few important pieces of information:\n","\n","- The first number tells us that there are 2 rows in **data_ndarray**.\n","- The second number tells us that there are 3 columns in **data_ndarray**.\n","\n","Let's confirm the number of number of rows and columns in our data set next.\n","\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Assign the shape of **taxi** to **taxi_shape**. Print the result."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tQvvuMfyJPK1","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0JjzlCZ2PjKB"},"source":["## 2.4 Selecting and Slicing Rows and Items from ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"0O8LgDyKDJP2","colab_type":"text"},"source":["\n","Let's look at a comparison between working with ndarray's and list of lists to select one or more rows of data:\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1jfWR9J9dsX2WhqSEnsTJMy_8x0NldSRT\">\n","\n","\n","As shown above, we can select rows in ndarrays very similarly to lists of lists. In reality, what we're seeing is a kind of shortcut. For any 2D array, the full syntax for selecting data is:\n","\n","```python\n","ndarray[row_index,column_index]\n","\n","# or if you want to select all\n","# columns for a given set of rows\n","ndarray[row_index]\n","```\n","\n","Where **row_index** defines the location along the row axis and **column_index** defines the location along the column axis.\n","\n","Like lists, array slicing is from the first specified index up to — but not including — the second specified index. For example, to select the items at index 1, 2, and 3, we'd need to use the slice [1:4].\n","\n","This is how we select a single item from a 2D ndarray:\n","\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1PZX6Ba54H6UM7NfnlyMkyoff5ZgMaSl9\">\n","\n","\n","With a list of lists, we use two separate pairs of square brackets back-to-back. With a NumPy ndarray, we use a single pair of brackets with comma separated row and column locations.\n","\n","Let's practice selecting one row, multiple rows, and single items from our **taxi** ndarray.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","1. From the **taxi** ndarray:\n","  - Select the row at index 0 and assign it to **row_0**.\n","  - Select every column for the rows at indexes 391 to 500 inclusive and assign them to **rows_391_to_500**.\n","  - Select the item at row index 21 and column index 5 and assign it to **row_21_column_5**\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ap1kpGqzTck6","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xcw6bRDVScBG"},"source":["## 2.5 Selecting Columns and Custom Slicing ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"qixhom3VEUTu","colab_type":"text"},"source":["\n","Let's continue by learning how to select one or more columns of data:\n","\n","\n","<img width=\"550\" src=\"https://drive.google.com/uc?export=view&id=1SMRvKH2kCSLpdANtxt4XZvSxomE0QgP5\">\n","\n","With a list of lists, we need to use a for loop to extract specific column(s) and append them back to a new list. With ndarray's, the process is much simpler. We again use single brackets with comma separated row and column locations, but we use a colon **(:)** for the row locations. This colon acts as a wildcard, and gives us all items in that dimension, or in other words all rows.\n","\n","If we wanted to select a partial 1D slice of a row or column, we can combine a single value for one dimension with a slice for the other dimension:\n","\n","<img width=\"550\" src=\"https://drive.google.com/uc?export=view&id=1ywqJGXCPuLD17sTVg8f_eIJHD4hiHM2D\">\n","\n","Lastly, if we wanted to select a 2D slice, we can use slices for both dimensions:\n","\n","\n","<img width=\"550\" src=\"https://drive.google.com/uc?export=view&id=1ag7hqo_71kgwLbhpo74rwQyKRA4Xjwpk\">\n","\n","\n","Let's practice everything we've learned so far to perform some more complex selections using NumPy\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","1. From the **taxi** ndarray:\n","  - Select every row for the columns at indexes 1, 4, and 7 and assign them to **columns_1_4_7.**\n","  - Select the columns at indexes 5 to 8 inclusive for the row at index 99 and assign them to **row_99_columns_5_to_8**.\n","  - Select the rows at indexes 100 to 200 inclusive for the column at index 14 and assign them to **rows_100_to_200_column_14**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XOKd8Xp4QS_7","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KiEmN57IUWcT"},"source":["## 2.6 Vector Math\n"]},{"cell_type":"markdown","metadata":{"id":"qUQwoUOvEoVG","colab_type":"text"},"source":["\n","The examples in the previous two sections showed us how much easier it is to select data using NumPy ndarrays. Beyond this, the selection we are making is a lot faster when working with vectorized operations. To illustrate this, we've created a random 5000000 x 5 numpy ndarray, and an equivalent list of of lists, and then a function to select the second and third columns for each:\n","\n","- **python_subset()**\n","- **numpy_subset()**\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3hZlSSJaWKK4","colab":{}},"source":["import numpy as np\n","\n","# create random (5000000,5) numpy arrays and \n","# list of lists\n","np_array = np.random.rand(5000000,5)\n","list_array = np_array.tolist()\n","\n","def python_subset():\n","    filtered_cols = []\n","    for row in list_array:\n","        filtered_cols.append([row[1],row[2]])\n","    return filtered_cols\n","\n","def numpy_subset():\n","    return np_array[:,1:3]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EymWEKoTdAEy"},"source":["We'll use a special iPython [%timeit](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit) magic command to time a single run of each function:"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1563738842110,"user_tz":180,"elapsed":33489,"user":{"displayName":"Ivanovitch Silva","photoUrl":"https://lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s64/photo.jpg","userId":"06428777505436195303"}},"id":"ga5qMuZsZav-","outputId":"d205247b-e917-4819-f212-7259027f9023","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%timeit -r 2 -n 10\n","# the number of executions will be n * r\n","\n","list_of_list = python_subset()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10 loops, best of 2: 1.58 s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1563738855500,"user_tz":180,"elapsed":1556,"user":{"displayName":"Ivanovitch Silva","photoUrl":"https://lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s64/photo.jpg","userId":"06428777505436195303"}},"id":"1aEZALVncAdO","outputId":"cf0bd194-9854-4fc9-b899-ca5911f670f7","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%%timeit -r 2 -n 10\n","# the number of executions will be n * r\n","\n","numpy_array = numpy_subset()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The slowest run took 6.56 times longer than the fastest. This could mean that an intermediate result is being cached.\n","10 loops, best of 2: 457 ns per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hm1MmQXIWJRp"},"source":["Our NumPy version was over $10^6$ times quicker than the list of lists version (the units of the output are in nanoseconds!!!)\n","\n","When we first talked about vectorized operations, we used the example of adding two columns of data. With data in a list of lists, we'd have to construct a for-loop and add each pair of values from each row individually. To refresh your memory, here's what our example code looked like:\n","\n","```python\n","my_numbers = [\n","              [6, 5],\n","              [1, 3],\n","              [5, 6],\n","              [1, 4],\n","              [3, 7],\n","              [5, 8],\n","              [3, 5],\n","              [8, 4]\n","             ]\n","\n","sums = []\n","\n","for row in my_numbers:\n","    row_sum = row[0] + row[1]\n","    sums.append(row_sum)\n","```\n","\n","At the time, we only talked about how vectorized operations make this faster, however it also makes our code to execute this much simpler. We'll break this down into three steps:\n","\n","- Convert our data to an ndarray,\n","- Select each column,\n","- Add the columns.\n","\n","Let's look at what that looks like in code:\n","\n","```python\n","# convert the list of lists to an ndarray\n","my_numbers = np.array(my_numbers)\n","\n","# select each of the columns - the result\n","# of each will be a 1D ndarray\n","col1 = my_numbers[:,0]\n","col2 = my_numbers[:,1]\n","\n","# add the two columns\n","sums = col1 + col2\n","```\n","\n","We could simplify this further if we wanted to:\n","\n","```python\n","sums = my_numbers[:,0] + my_numbers[:,1]\n","```\n","\n","Here are some key observations about this code:\n","\n","- When we selected each column, we used the syntax **ndarray[:,c]** where **c** is the column index we wanted to select. Like we saw in the previous screen, the colon acts as a wildcard and selects all rows.\n","- To add the two 1D ndarrays, **col1** and **col2** (which sometimes would be called **vectors** in this context), we simply use the addition operator **(+)** between them.\n","- The result of adding two 1D vectors is a 1D vector of the same shape (or dimensions) as the original.\n","\n","\n","Here's what happened behind the scenes:\n","\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=14pACrFQpoxcFg9esh3CyqrKTASHfjmvm\">\n","\n","\n","\n","What we just did, adding two columns (or vectors) together is called **vector math**. When we're performing vector math on two one-dimensional vectors, both vectors must have the same shape. We can use any of the standard [Python numeric operators](https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex) to perform vector math:\n","\n","- **vector_a + vector_b** - Addition\n","- **vector_a - vector_b** - Subtraction\n","- **vector_a \\* vector_b** - Multiplication (this is unrelated to the vector multiplication used in linear algebra).\n","- **vector_a / vector_b** - Division\n","- **vector_a % vector_b** - Modulus (find the remainder when **vector_a** is divided by **vector_b**)\n","- **vector_a \\*\\* vector_b** - Exponent (raise **vector_a** to the power of **vector_b**)\n","- **vector_a // vector_b** - Floor Division (divide **vector_a** by **vector_b**, rounding down to the nearest integer)\n","\n","Let's look at an example from our taxi dataset. Here are the first five rows of two of the columns in the data set:\n","\n","| trip_distance | trip_length |\n","|---------------|-------------|\n","| 21.00 | 2037.0 |\n","| 16.29 | 1520.0 |\n","| 12.70 | 1462.0 |\n","| 8.70 | 1210.0 |\n","| 5.56 | 759.0 |\n","\n","\n","Let's use these columns to calculate the average travel speed of each trip in miles per hour. The formula for calculating miles per hour is:\n","\n","$$\n","\\textrm{miles per hour} = \\textrm{distance in miles} \\div \\textrm{lenght in hours}\n","$$\n","\n","As we learned in the second screen of this mission, **trip_distance** is expressed in miles, and **trip_length** is seconds, so our first step is converting **trip_length** into hours. Here's how we would do it:\n","\n","```python\n","trip_distance = taxi[:,7]\n","trip_length_seconds = taxi[:,8]\n","\n","trip_length_hours = trip_length_seconds / 3600 # 3600 seconds is one hour\n","```\n","\n","Here we have a different example of vector math. We've divided a vector (one-dimensional array) by a scalar (single number). In this case, each value in the vector gets divided by the scalar to form the result.\n","\n","From here, let's perform vector division again to calculate the miles per hour.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","1. Use vector division to divide **trip_distance_miles** by **trip_length_hours**, assigning the result to **trip_mph**.\n","2. After you have run your code, inspect the contents of the new **trip_mph** variable."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2v5-hAbrV5lD","colab":{}},"source":["trip_distance_miles = taxi[:,7]\n","trip_length_seconds = taxi[:,8]\n","\n","trip_length_hours = trip_length_seconds / 3600 # 3600 seconds is one hour\n","\n","# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2E57euIQhMGi"},"source":["## 2.7 Arithmetic Numpy Functions\n"]},{"cell_type":"markdown","metadata":{"id":"4vA6gX-0J8uT","colab_type":"text"},"source":["\n","To make the calculations in the previous subsection, we used operators like the __/__ symbol to perform vectorized operations over our data. NumPy provides a second way to make these calculations - **arithmetic functions**. Let's look at how we would write the exercise from the previous screen with with the equivalent, the [numpy.divide](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.divide.html) function:\n","\n","```python\n","# using the `/` operator:\n","trip_mph_1 = trip_distance_miles / trip_length_hours\n","\n","# using the `numpy.divide()` function:\n","trip_mph_2 = np.divide(trip_distance_miles,trip_length_hours)\n","```\n","\n","The variables **trip_mph_1** and **trip_mph_2** will be identical.\n","\n","As you become more familiar with NumPy (and later, pandas), you'll find that there is often more than one way to do the same thing. Most of the time, which you choose is up to you. The general rule with situations like these it to choose the one that makes your code easier to read, which will pay dividends both as you start working with data in teams, and when you have to refer back to code you wrote some time ago. You will find that for these arithmetic operations, it's much more common to use the built-in Python operators than the functions.\n","\n","As you start to feel more comfortable with these libraries, you should start exploring the documentation. This is useful because it builds out your knowledge of available functions and methods, but also because it gets you used to reading the documentation. It's not possible to remember the syntax for every variation of every data science library, but if you remember what is possible, and can read the documentation, you'll always be able to quickly refamiliarize yourself with some syntax whenever you need it.\n","\n","You may have noticed that when we mention a function or method for the first time, we'll link to the documentation for it. Take a moment now to click the link for the [**numpy.divide()**](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.divide.html) function from the first paragraph of this screen and look at the documentation. It may seem a little overwhelming at first, but it is well worth your time.\n","\n","You might like to also take a look at all of the [arithmetic functions from the NumPy documentation](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.math.html#arithmetic-operations)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G89oOHVNiajY"},"source":["## 2.8 Calculating Statistics For 1D ndarrays\n","\n","Earlier, we created **trip_mph**, a 1D ndarray of the average mile-per-hour speed of each trip in our dataset, based off the **trip_length** and **trip_distance** columns. We might like to explore this data further, for instance working out what the maximum and minimum values are for that ndarray.\n","\n","We could use the built-in Python functions **min()** and **max()** to make these calculations, however these will perform calculations without taking advantage of vectorization. Instead we can use NumPy's ndarray methods we can use to calculate statistics.\n","\n","To calculate the minimum value of an 1D ndarray, we use the vectorized [ndarray.min()](http://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.min.html) method, like so:\n","\n","\n","```python\n","mph_min = trip_mph.min()\n","\n","mph_min\n","    0.0\n","```\n","\n","The minimum value in our **trip_mph** ndarray is **0.0**, for a trip that didn't travel any distance at all.\n","\n","Before we look at other array methods Let's take a moment to clarify the difference between **methods** and **functions**. Functions act as stand alone segments of code that usually take an input, perform some processing, and return some output. When we're working with Python lists, we can use the **len()** function to calculate the length of a list, but if we're working with Python strings, we can also use **len()**. In this case, it calculates the numbers of characters (or length) of the string.\n","\n","```python\n",">>> my_list = [21,14,91]\n",">>> len(my_list)\n","    3\n","\n",">>> my_string = 'Natal'\n",">>> len(my_string)\n","    5\n","```\n","\n","In contrast, methods are special functions that belong to a specific type of object. Python lists have a **list.append()** method that we can use to add an item to the end of a list. If we try to use that method on a string, we will get an error:\n","\n","```python\n",">>> my_list.append(21)\n","\n",">>> my_string.append(' is the best!')'\n","\n","    Traceback (most recent call last):\n","      File \"stdin\", line 1, in module\n","    AttributeError: 'str' object has no attribute 'append'\n","```\n","\n","When you're learning NumPy, this can get confusing, because sometimes there are operations that are implemented as both methods and functions, but sometimes there are not. Let's look at some examples:\n","\n","| Calculation | Function Representation | Method Representation |\n","|------------------------------------------------|-------------------------|-----------------------------------|\n","| Calculate the minimum value of **trip_mph** | np.min(trip_mph) | trip_mph.min() |\n","| Calculate the maximum value of **trip_mph** | np.max(trip_mph) | trip_mph.max() |\n","| Calculate the mean average value of **trip_mph** | np.mean(trip_mph) | trip_mph.mean() |\n","| Calculate the median average value of **trip_mph** | np.median(trip_mph) | There is no ndarray median method |\n","\n","\n","To remember the right terminology, anything that starts with np (e.g. **np.mean()**) is a function and anything you express with an object (or variable) name first (eg **trip_mph.mean()**) is a method. As we discussed in the previous section, where both exist it's up to you which you use, but it's much more common to see the method approach, and that's the one we'll use moving forward.\n","\n","Numpy ndarrays have methods for many different calculations. A few key methods are:\n","\n","- [ndarray.min()](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.min.html#numpy.ndarray.min) to calculate the minimum value\n","- [ndarray.max()](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.ndarray.max.html) to calculate the maximum value\n","- [ndarray.mean()](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.mean.html#numpy.ndarray.mean) to calculate the mean average value\n","- [ndarray.sum()](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.sum.html#numpy.ndarray.sum) to calculate the sum of the values\n","\n","You can see them a full list of ndarray methods in the NumPy ndarray [documentation](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.ndarray.html#calculation).\n","\n","Let's use the methods we've just learned about to calculate the smallest, largest, and mean average speed from our **trip_mph** ndarray.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","1. Use the [ndarray.max()](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.ndarray.max.html) method to calculate the maximum value of **trip_mph** and assign the result to **mph_max**. tip: see also ndarray.argmax() \n","2. Use the [ndarray.mean()](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.ndarray.mean.html#numpy.ndarray.mean) method to calculate the average value of **trip_mph** and assign the result to **mph_mean**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZS7d3jR8iD7N","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yfPU06uIlSUX"},"source":["## 2.9 Calculating Statistics For 2D ndarrays\n","\n","Looking at the result of the code in the previous screen, you would have observed:\n","\n","- Minimum trip speed: 0 mph\n","- Average (mean) trip speed (rounded): 32 mph\n","- Maximum trip speed (rounded): 82,000 mph\n","\n","While it's easy to imagine a case where the trip speed is 0 mph - a trip that starts and ends without traveling any distance, a trip speed of 82,000 mph is definitely not possible in New York traffic - that's almost 20x faster than the fastest plane in the world! This is could be due to an error in the devices that records the data, or perhaps errors made somewhere in the data pipeline. We'll spend some time later in this mission looking into the data that gave us this unrealistic number.\n","\n","For now, we're going to look at how we can calculate statistics for two-dimensional ndarrays. If we use the arrays without additional parameters, they will return a single value, just like they do with a 1D array:\n","\n","<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1hOKRuh4eN2_ZeiDOMT5ZwEz8syqMlB2X\">\n","\n","\n","But what if we wanted to find the maximum value of each row? For that, we need to use the **axis** parameter, and specify a value of **1**, which indicates we want to calculate values for each row.\n","\n","<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=151in-86Grb_igmMjTnMAHsuqu3XrxFiH\">\n","\n","If we want to find the maximum value of each column, we use an **axis** value of **0**:\n","\n","\n","<img width=\"550\" src=\"https://drive.google.com/uc?export=view&id=1tTSmu1P6FlOADhVrAJIL8ydgbX_ToT2m\">\n","\n","\n","To help you remember which is which, you can think of the first axis as rows, and the second axis as columns, just in the same way as when we're indexing a 2D NumPy array we use **ndarray[row,column]**. Then you think about which axis you want to apply the method along. The tricky part is to remember that when you apply the method along one axis, you get results in the other axis. Here is an illustration of that:\n","\n","\n","<img width=\"550\" src=\"https://drive.google.com/uc?export=view&id=11Yyylj-uQYHTDJcY-M5e8PMiiXydK4U8\">\n","\n","\n","Let's look at an example of from our taxi data set. Let's say that we wanted to do some validation, and check that the **total_amount** column is accurate. To remind ourselves of what the data looks like, let's look at the first five rows of columns with indexes 9 through 13:\n","\n","| fare_amount | fees_amount | tolls_amount | tip_amount | total_amount |\n","|-------------|-------------|--------------|------------|--------------|\n","| 52.0 | 0.8 | 5.54 | 11.65 | 69.99 |\n","| 45.0 | 1.3 | 0.00 | 8.00 | 54.3 |\n","| 36.5 | 1.3 | 0.00 | 0.00 | 37.8 |\n","| 26.0 | 1.3 | 0.00 | 5.46 | 32.76 |\n","| 17.5 | 1.3 | 0.00 | 0.00 | 18.8 |\n","\n","\n","We want to perform a check of whether the first 4 of these columns sums to the 5th column. This is how we would do it:\n","\n","\n","```python\n","# we'll compare against the first 5 rows only\n","taxi_first_five = taxi[:5]\n","# select these columns: fare_amount, fees_amount, tolls_amount, tip_amount\n","fare_components = taxi_first_five[:,9:13] \n","# select the total_amount column\n","fare_totals = taxi_first_five[:,13]\n","\n","# sum the component columns\n","fare_sums = fare_components.sum(axis=1)\n","\n","# compare the summed columns to the fare_totals\n","print(fare_totals.round())\n","print(fare_sums)\n","```\n","\n","Our code outputs the following:\n","\n","```python\n","[ 69.99  54.3   37.8   32.76  18.8 ]\n","[ 69.99  54.3   37.8   32.76  18.8 ]\n","```\n","\n","We have validated that our **fare_totals** column is correct (at least for the first five rows).\n","\n","Now, let's practice calculating the average for each column:\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","1. Using a single method, calculate the mean value for each column of **taxi**, and assign the result to **taxi_column_means.**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hNn14CmBl3d9","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2Vwb6FEzof6V"},"source":["## 2.10 Adding Rows and Columns to ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"HWPUoa4XLi_-","colab_type":"text"},"source":["\n","Earlier in this lesson, we produced a ndarray **trip_mph** of the average speed of each trip. We also observed that the maximum speed was 82,000 mph, which is definitely not an accurate number. To take a closer look at why we might be getting this value, we're going to do the following:\n","\n","- Add the **trip_mph** as a column to our **taxi** ndarray.\n","- Sort taxi by **trip_mph**.\n","- Look at the rows with the highest **trip_mph** from our sorted ndarray to see what they tell us about these large values.\n","\n","\n","To start, let's learn how to add rows and columns to an ndarray. The technique we're going to use involves the [numpy.concatenate() function](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.concatenate.html). This function accepts:\n","\n","- A list of ndarrays as the first, unnamed parameter.\n","- An integer for the **axis** parameter, where 0 will add rows and 1 will add columns.\n","\n","The **numpy.concatenate()** function requires that each array have the same shape, excepting the dimension corresponding to **axis**. Let's look at an example to understand more precisely how that works. We have two arrays, **ones** and **zeros**:\n","\n","```python\n",">>> print(ones)\n","\n","    [[ 1  1  1]\n","     [ 1  1  1]]\n","\n",">>> print(zeros)\n","\n","    [ 0  0  0]\n","```\n","\n","Let's try and use **numpy.concatenate()** to add **zeros** as a row. Because we are wanting to add a row, we use **axis=0**\n","\n","```python\n",">>> combined = np.concatenate([ones,zeros],axis=0)\n","\n","    Traceback (most recent call last):\n","      File \"stdin\", line 1, in module\n","    ValueError: all the input arrays must have same number of dimensions\n","```\n","\n","We've got an error because our dimensions don't match - let's look at the shape of each array to see if we can understand why:\n","\n","```python\n",">>> print(ones.shape)\n","\n","    (2, 3)\n","\n",">>> print(zeros.shape)\n","\n","    (3,)\n","```\n","\n","Because we're using **axis=0**, our shapes have to match across all dimensions except the first. If we look at these two array's we can see that the second dimension of **ones** is 3, but **zeros** doesn't have a second dimension, because it's only a 1D array. This is the source of our error. The table below shows the shapes we need to be able to combine these arrays.\n","\n","\n","| Object | Current shape | Desired Shape |\n","|--------|---------------|---------------|\n","| ones | (2, 3) | (2, 3) |\n","| zeros | (3,) | (1, 3) |\n","\n","\n","In order to adjust the shape of **zeros**, we can use the [numpy.expand_dims()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html) function. You might like to follow these steps in the cell. We'll start by passing **axis=0** because we want to convert our 1D array into a 2D array representing a row:\n","\n","\n","```python\n",">>> zeros_2d = np.expand_dims(zeros,axis=0)\n","\n",">>> print(zeros_2d)\n","\n","    [[ 0  0  0]]\n","\n",">>> print(zeros_2d.shape)\n","\n","    (1, 3)\n","```\n","\n","Finally, we can use **numpy.concatenate()** to combine the two arrays:\n","\n","```python\n",">>> combined = np.concatenate([ones,zeros_2d],axis=0)\n","\n",">>> print(combined)\n","\n","    [[ 1  1  1]\n","     [ 1  1  1]\n","     [ 0  0  0]]\n","```\n","\n","Adding a column is done the same way, except substituting **axis=1** for **axis=0** in both functions. The initial code for this screen shows this process.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","1. Expand the dimensions of **trip_mph** to be a single column in a 2D ndarray, and assign the result to **trip_mph_2d**.\n","2. Add **trip_mph_2d** as a new column at the end of **taxi**, assigning the result back to **taxi**.\n","3. Use the **print()** function to display **taxi** and view the new column.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8Dlkj-iq1ynO","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"60IwLRaD2mfm"},"source":["## 2.11 Sorting ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"fNCWlEP-Llhu","colab_type":"text"},"source":["\n","Now that we've added our **trip_mph** column to our array, our next step is to sort the array. For this, we'll use the [numpy.argsort() function](http://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.argsort.html#numpy.argsort). The **numpy.argsort()** function returns the indices which would sort an array. Don't worry if that sounds a little unusual, we'll look at an example to help explain it.\n","\n","We'll start by defining a simple 1D ndarray, where each item is a string containing the name of a fruit:\n","\n","<img width=\"450\" src=\"https://drive.google.com/uc?export=view&id=1xep-cNIjyRLiSjj40rH7FBI-JsxGZjEr\">\n","\n","We've put the indices, or index numbers, next to each value in the array. We use the indices whenever we want to select an item, for instance **fruit[2]** would return the value **'apple'** and **fruit[1]** would return the value **'banana'**. As we learned earlier in the mission, if we selected using a list of values like **fruit[[2,1]]**, we would get back an ndarray of those values in the order: **['apple','banana'].**\n","\n","Next, we'll use **numpy.argsort()** to return the indices that would sort the array:\n","\n","<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1_2PNcK3Ty6blapVQBHg1efLPr_QGJAy5\">\n","\n","\n","If we look at these indices carefully, we can see what has happened. The first value of **sorted_order** is 2: The value at index 2 of fruit is **'apple'**, the first item if we sort in alphabetical order. The second value is 1: The value and index 1 of fruit is **'banana'**, the second item if we sort in alphabetical order, and so on.\n","\n","If we use the array of sorted indices to select items from fruit, here is what we get:\n","\n","<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1CTtkZu4vHHwTAovRdWeEqPhwuV3jH9Ls\">\n","\n","\n","In the code above, the values from **sorted_order** get inserted between the brackets. The code is the equivalent of:\n","\n","```python\n","sorted_fruit = fruit[[2, 1, 4, 3, 0]]\n","```\n","\n","As you can see, the result is that our original array has been sorted in alphabetical order.\n","\n","Let's look at an example with a 2D ndarray. We'll sorting a 5x5 ndarray called int_square by it's last column:\n","\n","\n","```python\n",">>> print(int_square)\n","\n","    [[5 2 8 3 4]\n","     [2 8 6 2 5]\n","     [1 6 2 7 7]\n","     [0 7 7 4 5]\n","     [5 7 1 1 2]]\n","```\n","\n","We'll start by selecting just the last column.\n","\n","```python\n",">>> last_column = int_square[:,4]\n","\n",">>> print(last_column)\n","\n","    [4 5 7 5 2]\n","```\n","\n","Then, we use **numpy.argsort()** to get the indices that would sort the last column and assign them to **sorted_order**.\n","\n","```python\n",">>> sorted_order = np.argsort(last_column)\n","\n",">>> print(sorted_order)\n","\n","    [4 0 1 3 2]\n","```\n","\n","As a test, let's use **sorted_order** to sort just the last column:\n","\n","```python\n",">>> last_column_sorted = last_column[sorted_order]\n","\n",">>> print(last_column_sorted)\n","\n","    [2 4 5 5 7]\n","```\n","\n","Finally, we can pass **sorted_order** to sort to the full ndarray:\n","\n","```python\n",">>> int_square_sorted = int_square[sorted_order]\n","\n",">>> print(int_square_sorted)\n","\n","    [[5 7 1 1 2]\n","     [5 2 8 3 4]\n","     [2 8 6 2 5]\n","     [0 7 7 4 5]\n","     [1 6 2 7 7]]\n","```\n","\n","We can use the same technique to sort our **taxi** ndarray by the **trip_mph** column. NumPy only supports sorting in ascending order, however that is not a problem - we'll just look at the last few rows instead of the first few rows to examine the data we need.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","1. Use **numpy.argsort()** to get the indices which would sort the **trip_mph** column from the **taxi** ndarray. The **trip_mph** column is at column index **15**.\n","2. Use the indices from the previous instruction to **sort** the **taxi** ndarray, and assign the result to **taxi_sorted**.\n","3. Use the **print()** function to examine the **taxi_sorted** ndarray."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aJSDV5D53GjH","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cmvyPsCU7VWX"},"source":["In this section we learned:\n","\n","- How vectorization it makes our code faster.\n","- About n-dimensional arrays, and NumPy's ndarrays.\n","- How to select specific items, rows, columns, 1D slices, and 2D slices from ndarrays.\n","- How to use vector math to apply simple calculations to entire ndarrays.\n","- How to use vectorized methods to perform calculations across either axis of ndarrays.\n","- How to add extra columns and rows to ndarrays.\n","- How to sort an ndarray."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"n2uqv_cV7Yfa","toc-hr-collapsed":true},"source":["\n","# 3. Boolean Indexing with NumPy"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7UhZsKKiSR6c"},"source":["## 3.1 Reading CSV files with NumPy\n"]},{"cell_type":"markdown","metadata":{"id":"7yrLsviAmxwX","colab_type":"text"},"source":["\n","In the previous section we learned how to use NumPy and ndarrays to perform vectorized operations to work with data. We learned that NumPy makes it quick and easy to make selections of our data, and includes a number of functions and methods that make it easy to calculate statistics across the different axes (or dimensions).\n","\n","Using the skills we've learned so far, we were able to select subsets of our taxi trip data and then calculate things like the maximum, minimum, sum, and mean of various columns and rows. But what if we wanted to find out how many trips were taken in each month? Or which airport is the busiest? For this we will need a new technique: **Boolean Indexing.**\n","\n","In the previous section, we used Python's built-in [csv module](https://docs.python.org/3/library/csv.html) to import our CSV as a 'list of lists' and used loops to convert each value to a float before we created our NumPy ndarray. Now that we understand NumPy a little better, let's learn about the [numpy.genfromtxt() function](http://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) to read in files.\n","\n","The **numpy.genfromtxt()** function reads a text file into a NumPy ndarray. While it has over 20 parameters, for most cases you need only two. Here is the simplified syntax for the function, and an explanation of the two parameters:\n","\n","```python\n","np.genfromtxt(filename,delimiter)\n","```\n","\n","- **filename** - A positional argument, usually a string representing the path to the text file to be read.\n","- **delimiter** - A named argument, specifying the string used to separate each value.\n","In this case, because we have a CSV file, the delimiter is a comma. Let's look at what the code would look like to read in the **nyc_taxis.csv** file.\n","\n","```python\n","taxi = np.genfromtxt('nyc_taxis.csv', delimiter=',')\n","print(taxi)\n","```\n","\n","The output of this code is shown below:\n","\n","```python\n","[[   nan    nan    nan ...,    nan    nan    nan]\n"," [  2016      1      1 ...,  11.65  69.99      1]\n"," [  2016      1      1 ...,      8   54.3      1]\n"," ..., \n"," [  2016      6     30 ...,      5  63.34      1]\n"," [  2016      6     30 ...,   8.95  44.75      1]\n"," [  2016      6     30 ...,      0  54.84      2]]\n","```\n","\n","When **numpy.genfromtxt()** reads in a file, it attempts to determine the data type of the file by looking at the values. We can use the **ndarray.dtype** attribute to see the internal datatype that has been used.\n","\n","```python\n",">>> taxi.dtype\n","\n","    float64\n","```\n","\n","NumPy has chosen the **float64** type as it will allow most of the values from our CSV to be read. You can think of NumPy's **float64** type as being identical to Python's float type (the **'64'** refers to the number of bits used to store the underlying value).\n","\n","The first row of our data contains a value that we haven't seen before: **nan**. **NaN** is an acronym for **Not a Number**. The concept of NaN is an unusual one at first - it literally means that the value cannot be stored as a number. It is similar to (and often refered to interchangably as a) null value, like Python's [None constant](https://docs.python.org/3.4/library/constants.html#None).\n","\n","NaN is most commonly seen when a value is missing, but in this case we have NaN because the first line from our CSV file contains the names of each column. As we mentioned in the previous mission, NumPy ndarrays can contain only one type. NumPy is unable to convert string values like **pickup_year** into the **float64** data type. Later in this course we'll talk about NaN some more in the context of missing values. For now, we need to remove this row from our ndarray. We can do this the same way we would if our data was stored in a list of lists:\n","\n","```python\n","taxi = taxi[1:]\n","```\n","\n","Which removes the first row from the array. Alternatively, we can pass an additional parameter, **skip_header**, to the **numpy.genfromtext()** function. The **skip_header** parameters accepts an integer, the number of rows from the start of the file to skip (note that because this is the number of rows and not the index, to skip the first row would require a value of 1 and not 0).\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","1. Import the **NumPy** library.\n","2. Use the **numpy.genfromtxt()** function to read the **nyc_taxis.csv** file into NumPy, skipping the first row, and assign the result to **taxi**.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-O1wB378VMTp","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eiog2pE7Wa-p"},"source":["## 3.2 Boolean Arrays\n"]},{"cell_type":"markdown","metadata":{"id":"rQCzFiVzo3b-","colab_type":"text"},"source":["\n","In the last sections we mentioned five ways to index, or select, data from ndarrays:\n","\n","- An **integer**, indicating a specific location.\n","- A **slice**, indicating a range of locations.\n","- A **colon**, indicating every location.\n","- A **list of values**, indicating specific locations.\n","- A **boolean array**, indicating specific locations.\n","\n","In this section we're going to focus on the last and arguably the most powerful method, the boolean array. A boolean array, as the name suggests is an array full of boolean values. Boolean arrays are sometimes called boolean vectors or boolean masks.\n","\n","Let's take a moment to refresh our understanding of what a boolean value is. The boolean (or **bool**) type is a built-in Python type that can contain one of two unique values:\n","\n","- True\n","- False\n","\n","\n","Boolean values can be defined either by **'hard-coding'** them to the code using the keywords **True** or **False**, or alternatively by using any of the Python comparison operators like **== (equal) > (greater than), < (less than), != (not equal)**. They're commonly seen within if statements, like the example below:\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1cltwKCELwoqrOzBNU7AIDsJ083ykMhPL\">\n","\n","As the code is executed the boolean operation is evaluated, causing the print function to run. We can use the console to perform simple boolean operations as well:\n","\n","```python\n",">>> type(3.5) == float\n","    True\n",">>> 3 < 10\n","    True\n",">>> \"hello\" == \"goodbye\"\n","    False\n",">>> 5 > 6\n","    False\n",">>> (3 + 3) != 5\n","    True\n","```\n","\n","When we explored vector math in the first section, we learned that an operation between a ndarray and a scalar (individual) value results in a new ndarray:\n","\n","\n","```python\n",">>> np.array([2,4,6,8]) + 10\n","\n","    array([12, 14, 16, 18])\n","```\n","\n","The **+ 10** operation is applied to each value in the array.\n","\n","Now, let's look at what happens when we perform a boolean operation between an ndarray and a scalar:\n","\n","```python\n",">>> np.array([2,4,6,8]) < 5\n","\n","    array([ True,  True, False, False], dtype=bool)\n","```\n","\n","A similar pattern occurs– the 'less than five' operation is applied to each value in the array. The diagram below shows this step by step:\n","\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1QINhkJfEHn-CXbppP-x-RklfQCxfKrxg\">\n","\n","Let's practice using vectorized boolean operations to create some boolean arrays.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","1. Use vectorized boolean operations to:\n","  - Evaluate whether the elements in array __a__ are less than 3 and assign the result to **a_bool**.\n","  - Evaluate whether the elements in array __b__ are equal to **\"blue\"** and assign the result to **b_bool**.\n","  - Evaluate whether the elements in array __c__ are greater than 100 and assign the result to **c_bool**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jO8tMUxgXtH9","colab":{}},"source":["a = np.array([1, 2, 3, 4, 5])\n","b = np.array([\"blue\", \"blue\", \"red\", \"blue\"])\n","c = np.array([80.0, 103.4, 96.9, 200.3])\n","\n","# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JtRNFR1IZMkY"},"source":["## 3.3 Boolean Indexing with 1D ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"RK81TV-SppU0","colab_type":"text"},"source":["\n","Now we know what a boolean array is and how to create one using vectorized boolean operations. The last piece of the puzzle is understanding how to index (or select) using boolean arrays. This is known as boolean indexing. Let's use one of the examples from the previous screen.\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1nNX9HUvygkpb2_GowE6t3QPtozu4TaX6\">\n","\n","\n","To index using our new boolean array, we simply insert it in the square brackets, just like we would do with our other selection techniques:\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1HruGF2TejcaPODJP0PvLqNj2g9qNoRVQ\">\n","\n","The boolean array acts as a filter, and the values that correspond to **True** become part of the resultant ndarray, where the the values that correspond to **False** are removed.\n","\n","Now, let's look at an example using our **taxi** data. The second column in the ndarray is **pickup_month**. Let's use boolean indexing to create a filtered ndarray containing only items where the value is **1**, which corresponds to January. Once we have done that, we can look at the [ndarray.shape attribute](http://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.ndarray.shape.html) for the filtered ndarray, which will tell us the number of taxi rides in our data set from the month of January.\n","\n","We'll do it step by step, starting with selecting just the **pickup_month** column:\n","\n","```python\n","pickup_month = taxi[:,1]\n","```\n","\n","Next, we use a boolean operation to make our boolean array:\n","\n","```python\n","january_bool = pickup_month == 1\n","```\n","\n","Then we use the new boolean array to select only the items from pickup_month that have a value of 1:\n","\n","```python\n","january = pickup_month[january_bool]\n","```\n","\n","Finally, we use the **.shape** attribute to find out how many items are in our **january** ndarray which is the number of taxi rides in our data set from the month of January. We'll use **[0]** to extract the value from the tuple returned by **.shape**\n","\n","```python\n","january_rides = january.shape[0]\n","print(january_rides)\n","\n","13481\n","```\n","\n","There are 13,481 rides in our dataset from the month of January. Let's practice boolean indexing and find out the number of rides in our data set for February and March.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","tip: details about the [dataset](https://docs.google.com/document/d/1zLZspwkGFjrqpspkZNipIM0790gPI1-rMhOcIsUmD7A/edit?usp=sharing)\n","1. Calculate the number of rides in the **taxi** ndarray that are from February:\n","  - Create a boolean array, **february_bool**, that evaluates whether the items in **pickup_month** are equal to **2**.\n","  - Use the **february_bool** boolean array to index **pickup_month**, and assign the result to **february**.\n","  - Use the **ndarray.shape** attribute to find the number of items in **february** and assign the result to **february_rides**.\n","2. Calculate the number of rides in the **taxi** ndarray that are from March:\n","  - Create a boolean array, **march_bool**, that evaluates whether the items in **pickup_month** are equal to **3**.\n","  - Use the **march_bool** boolean array to index **pickup_month**, and assign the result to **march.**\n","  - Use the **ndarray.shape** attribute to find the number of items in **march** and assign the result to **march_rides**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Oe774EHdZesb","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fIFdBexgcYE2"},"source":["## 3.4 Boolean Indexing with 2D ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"NqlL9LcjpObo","colab_type":"text"},"source":["\n","When working with 2D ndarray, you can use boolean indexing in combination with any of the indexing methods we learned in the previous mission. The only limitation is that the boolean array must have the same length as the dimension you're indexing. Let's look at some examples:\n","\n","<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1jXwHlU2lUX-VHmCTm9brDiTRu8L7yx2t\">\n","\n","Because a boolean array contains no information about how it was created, we can use a boolean array made from just one column of our array to index the whole array.\n","\n","Let's look at an example from our taxi trip data. In the previous mission, we sorted our ndarray in order to view the trips that had very large average speeds. Boolean indexing makes this much easier:\n","\n","```python\n","# calculate the average speed\n","trip_mph = taxi[:,7] / (taxi[:,8] / 3600)\n","\n","# create a boolean array for trips with average\n","# speeds greater than 20,000 mph\n","trip_mph_bool = trip_mph > 20000\n","\n","# use the boolean array to select the rows for\n","# those trips, and the pickup_location_code,\n","# dropoff_location_code, trip_distance, and\n","# trip_length columns\n","trips_over_20000_mph = taxi[trip_mph_bool,5:9]\n","\n","print(trips_over_20000_mph)\n","```\n","\n","```python\n","[[     2      2     23      1]\n"," [     2      2   19.6      1]\n"," [     2      2   16.7      2]\n"," [     3      3   17.8      2]\n"," [     2      2   17.2      2]\n"," [     3      3   16.9      3]\n"," [     2      2   27.1      4]]\n","```\n","\n","Combining our boolean array with a column slice allowed us to view just the key data of these trips with very high average speeds. As we observed in the previous mission, all of these trips have the same pickup and dropoff locations, and last only a few seconds.\n","\n","Let's use this technique to examine the rows that have the highest values for the **tip_amount** column.\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","1. Create a boolean array, **tip_bool**, that determines which rows have values for the **tip_amount** column of more than **50**.\n","2. Use the **tip_bool** array to select all rows from **taxi** with values tip amounts of more than **50**, and the columns from indexes 5 to 13 inclusive. Assign the resulting array to **top_tips.**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c4hpf4SFc2JE","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9ijCY7tXewNH"},"source":["## 3.5 Assigning Values in ndarrays\n"]},{"cell_type":"markdown","metadata":{"id":"UGpha0xEpQZW","colab_type":"text"},"source":["\n","So far we've learned how to retrieve data from ndarrays, and how to add rows or columns. There is one missing piece to our NumPy fundamentals toolbox: modifying values.\n","\n","We can use the same indexing techniques we've already learned to assign values within an ndarray. The syntax we'll use (in pseudocode) is:\n","\n","```python\n","ndarray[location_of_values] = new_value\n","```\n","\n","Let's take a look at what that looks like in actual code. With our 1D array, we can specify one specific index location:\n","\n","```python\n","a = np.array(['red','blue','black','blue','purple'])\n","a[0] = 'orange'\n","print(a)\n","\n","['orange', 'blue', 'black', 'blue', 'purple']\n","```\n","\n","Or we can assign multiple values at once:\n","\n","```python\n","a[3:] = 'pink'\n","print(a)\n","\n","['orange', 'blue', 'black', 'pink', 'pink']\n","```\n","\n","With a 2D ndarray, just like with a 1D, we can assign one specific index location.\n","\n","```python\n","ones = np.array([[1, 1, 1, 1, 1],\n","                 [1, 1, 1, 1, 1],\n","                 [1, 1, 1, 1, 1]])\n","ones[1,2] = 99\n","print(ones)\n","\n","[[ 1,  1,  1,  1,  1],\n"," [ 1,  1, 99,  1,  1],\n"," [ 1,  1,  1,  1,  1]]\n","```\n","\n","We can also assign a whole row...\n","\n","```python\n","ones[0] = 42\n","print(ones)\n","\n","[[42, 42, 42, 42, 42],\n"," [ 1,  1, 99,  1,  1],\n"," [ 1,  1,  1,  1,  1]]\n","```\n","\n","...or a whole column:\n","\n","```python\n","ones[:,2] = 0\n","print(ones)\n","\n","[[42, 42, 0, 42, 42],\n"," [ 1,  1, 0,  1,  1],\n"," [ 1,  1, 0,  1,  1]]\n","```\n","\n","Let's practice some array assignment with our taxi dataset.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","To help you practice without making changes to our original array, we have used the [ndarray.copy()](http://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.ndarray.copy.html#numpy.ndarray.copy) method to make **taxi_modified**, a copy of our original for these exercises.\n","\n","\n","- The value at column index 5 (**pickup_location**) of row index 28214 is incorrect. Use assignment to change this value to __1__ in the **taxi_modified** ndarray.\n","- The first column (index 0) contains year values as four digit numbers in the format YYYY (2016, since all trips in our data set are from 2016). Use assignment to change these values to the YY format (16) in the **taxi_modified** ndarray.\n","- The values at column index 7 (**trip_distance**) of rows index 1800 and 1801 are incorrect. Use assignment to change these values in the **taxi_modified** ndarray to the mean value for that column.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WYq6mBYsgXGe","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X6ayoyibggDV"},"source":["## 3.6 Assignment Using Boolean Arrays\n"]},{"cell_type":"markdown","metadata":{"id":"U0Ao_tzvpUGw","colab_type":"text"},"source":["\n","Boolean arrays become very powerful when we use them for assignment. Let's start by looking at a simple example:\n","\n","```python\n",">>> a = np.array([1, 2, 3, 4, 5])\n","\n",">>> a[a > 2] = 99\n","\n",">>> print(a)\n","\n","    [ 1  2 99 99 99]\n","```\n","\n","Before we walk through how the code works, we've just seen a 'shortcut' for the first time. The second line of code inserted the definition of the boolean array directly into the selection. This 'shortcut' way is the conventional way to write boolean indexing. Up until now, we've been taking the extra step of assigning to an intermediate variable first so that the process is clear. Let's look at how we would have written the example using the intermediate variable.\n","\n","```python\n",">> a2 = np.array([1, 2, 3, 4, 5])\n","\n",">> a2_bool = a2 > 2\n","\n",">> a2[a2_bool] = 99\n","\n",">> print(a2)\n","\n","    [ 1  2 99 99 99]\n","```\n","\n","You can see that both ways produce the same results. From here on, we will use the shortcut method instead of the intermediate variable. The boolean array controls the values that the assignment applies to, and the other values remain unchanged. Let's look at how this code works:\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1u8WcLq-TYCIhSFuEa9ElfMFYPBAC_rZZ\">\n","\n","\n","Next, let's look at an example of assignment using a boolean array with two dimensions:\n","\n","```python\n",">>> b = np.array([[1, 2, 3],\n","                  [4, 5, 6],\n","                  [7, 8, 9]])\n","\n",">>> b[b > 4] = 99\n","\n",">>> print(b)\n","\n","    [[ 1  2  3]\n","     [ 4 99 99]\n","     [99 99 99]]\n","```\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1VPmK9UuV1jvX74-ljHWJT6oE_vkTkS-a\">\n","\n","\n","Lastly, let's look at an example that uses a 1D boolean array to perform assignment on a 2D array:\n","\n","```python\n",">>> c = np.array([[1, 2, 3],\n","                  [4, 5, 6],\n","                  [7, 8, 9]])\n","\n",">>> c[c[:,1] > 2, 1] = 99\n","\n",">>> print(c)\n","\n","    [[ 1  2  3]\n","     [ 4 99  6]\n","     [ 7 99  9]]\n","```\n","\n","\n","In this example, the **c[:,1] > 2** boolean operation compares just one column's values and produces a 1D boolean array. We then use that boolean array to specify the rows for assignment, and use the integer **1** to specify the second column. This results in our boolean array only being applied to the second column, with all other values remaining unchanged:\n","\n","<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1nXvILrVeMLryXgLr_TYLHPdjHVJZxstA\">\n","\n","\n","This pattern, where a 1D boolean array is used to specify assignment in the row dimension and an index value is used to specify which column the array applies to is very common. The pseudocode syntax for this pattern is as follows, first using an intermediate variable:\n","\n","```python\n","bool = array[:, column_for_comparison] == value_for_comparison\n","array[bool, column_for_assignment] = new_value\n","```\n","\n","and then all in one line:\n","\n","```python\n","array[array[:, column_for_comparison] == value_for_comparison, column_for_assignment] = new_value\n","```\n","\n","Let's practice this pattern using our taxi data set:\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","We have created a new copy of our taxi dataset, **taxi_modified** with an additional column containing the value 0 for every row.\n","\n","1. In our new column at index **15**, assign the value __1__ if the **pickup_location_code** (column index 5) corresponds to an airport location, leaving the value as 0 otherwise by performing these three operations:\n","  - For rows where the value for the column index 5 is equal to 2 (JFK Airport), assign the value 1 to column index 15.\n","  - For rows where the value for the column index 5 is equal to 3 (LaGuardia Airport), assign the value 1 to column index 15.\n","  - For rows where the value for the column index 5 is equal to 5 (Newark Airport), assign the value 1 to column index 15."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2JQlbhGOhEq6","outputId":"5bfa03d9-b8d5-4106-9d8b-1234f5e16ba3","colab":{}},"source":["# this creates a copy of our taxi ndarray\n","taxi_modified = taxi.copy()\n","\n","# create a new column filled with `0`.\n","zeros = np.zeros([taxi_modified.shape[0], 1])\n","taxi_modified = np.concatenate([taxi, zeros], axis=1)\n","print(taxi_modified)\n","\n","# put your code here"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(89560, 16)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sVxqb-Z8jYU0"},"source":["## 3.7 Challenge: Which is the most popular airport?\n"]},{"cell_type":"markdown","metadata":{"id":"GAZubMCxpZsf","colab_type":"text"},"source":["\n","We'll conclude this lesson with two challenges. Challenges are designed to help you practice the techniques you've learned in this lesson.\n","\n","**Don't be discouraged if these challenge steps take a few attempts to get right– working with data is an iterative process!**\n","\n","In this challenge, we want to find out which airport is the most popular destination in our data set. To do that, we'll use boolean indexing and the **dropoff_location_code** column (column index 6) to create three filtered arrays and then look at how many rows are in each array. The values from the column we're interested in are:\n","\n","- 2 - JFK Airport.\n","- 3 - LaGuardia Airport.\n","- 5 - Newark Airport.\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","- Using the original **taxi** ndarray, calculate how many trips had JFK Airport as their destination:\n","  - Select only the rows there the **dropoff_location_code** column has a value that corresponds to JFK, and assign the result to **jfk**.\n","  - Calculate how many rows are in the new **jfk** array and assign the result to **jfk_count**.\n","- Calculate how many trips from **taxi** had Laguardia Airport as their destination:\n","    - Select only the rows there the **dropoff_location_code** column has a value that corresponds to Laguardia, and assign the result to **laguardia.**\n","    - Calculate how many rows are in the **new laguardia** array and assign the result to **laguardia_count.**\n","- Calculate how many trips from **taxi** had Newark Airport as their destination:\n","  - Select only the rows there the **dropoff_location_code** column has a value that corresponds to Newark, and assign the result to **newark.**\n","  - Calculate how many rows are in the **new newark array** and assign the result to **newark_count.**\n","- After you have run your code, inspect the values for **jfk_count**, **laguardia_count**, and **newark_count** and see which airport has the most dropoffs."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cspm1j7tlB_a","colab":{}},"source":["# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i82V4R4ulML5"},"source":["## 3.8 Challenge: Calculating Statistics for Trips on Clean Data\n"]},{"cell_type":"markdown","metadata":{"id":"5wfOb5ozpevR","colab_type":"text"},"source":["\n","Our calculations in the previous screen show that Laguardia is the most common airport for dropoffs in our data set.\n","\n","Our second and final challenge involves removing potentially bad data from our data set, and then calculating some descriptive statistics on the remaining 'clean' data.\n","\n","We'll start by using boolean indexing to remove any rows that have an average speed for the trip greater than 100 mph (160 kph) which should remove the questionable data we have worked with over the past two missions. Then, we'll use array methods to calculate the mean for specific columns of the remaining data. The columns we're interested in are:\n","\n","- **trip_distance**, at column index 7\n","- **trip_length**, at column index 8\n","- **total_amount**, at column index 13\n","- **trip_mph**, not available as a column but as its own ndarray\n","\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","The **trip_mph** ndarray has been provided for you.\n","\n","- Create a new ndarray, **cleaned_taxi**, containing only rows for which the values of **trip_mph** are less than 100.\n","- Calculate the mean of the **trip_distance** column of **cleaned_taxi**, and assign the result to **mean_distance**.\n","- Calculate the mean of the **trip_length** column of **cleaned_taxi**, and assign the result to **mean_length**.\n","- Calculate the mean of the **total_amount** column of **cleaned_taxi**, and assign the result to **mean_total_amount.**\n","- Calculate the mean of the **trip_mph**, excluding values greater than 100, and assign the result to **mean_mph**."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x6vpsYfElmQB","colab":{}},"source":["trip_mph = taxi[:,7] / (taxi[:,8] / 3600)\n","\n","# put your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KwD_Tt6pmXk7"},"source":["In this section we learned:\n","\n","- How to use **numpy.genfromtxt()** to read in an ndarray.\n","- About **NaN** values.\n","- What a boolean array is, and how to create one.\n","- How to use boolean indexing to filter values in one and two-dimensional ndarrays.\n","- How to assign one or more new values to an ndarray based on their locations.\n","- How to assign one or more new values to an ndarray based on their values.\n","\n","This is the last section that deals exclusively with NumPy, however it's certainly not the last time we'll use NumPy. As we move onto using pandas, and later in our learning paths other Python data libraries, you'll see that a lot of the concepts we've learned transfer, and you'll also find yourself using a lot of these fundamental NumPy concepts. We'll also use NumPy from time to time to create, transform and otherwise work with tabular data.\n"]}]}